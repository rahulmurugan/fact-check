{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rahul/Desktop/fact_check/fact-check\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Ensure the project root is on the Python path so that our custom modules can be imported.\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "\n",
    "# Import our LangChain and custom modules.\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline\n",
    "\n",
    "from src.utils import setup_logger, save_json\n",
    "\n",
    "\n",
    "\n",
    "# Set up our logger.\n",
    "logger = setup_logger(\"main_rag\", level=20)\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 19:44:22,704 - main_rag - INFO - Loaded 8 clinical documents.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clinical_docs_dir = os.path.join(\"data\", \"Clinical Files\")\n",
    "\n",
    "#  to load clinical documents\n",
    "loader = DirectoryLoader(clinical_docs_dir)\n",
    "documents = loader.load()\n",
    "\n",
    "logger.info(f\"Loaded {len(documents)} clinical documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 19:44:47,197 - main_rag - INFO - Split documents into 676 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "logger.info(f\"Split documents into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 19:44:57,106 - main_rag - INFO - FAISS vectorstore created from document chunks.\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a vector store (FAISS index) from the document chunks using our embeddings.\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "logger.info(\"FAISS vectorstore created from document chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# my_prompt = PromptTemplate(\n",
    "#     template=\"\"\"\n",
    "# You are a fact-checking assistant. Your task is to find the sentences, tables, or figures \n",
    "# in the context that best support the following claim.\n",
    "\n",
    "# Claim: {query}\n",
    "\n",
    "# Context:\n",
    "# {context}\n",
    "\n",
    "# Identify and return only the exact text from the context that supports the claim.\n",
    "# \"\"\",\n",
    "#     # The variables that will be substituted in the template\n",
    "#     input_variables=[\"context\", \"query\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 20:11:14,194 - main_rag - INFO - RetrievalQA chain set up.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model_id, max_length=256, device=-1)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# # Define a prompt template for the RetrievalQA chain. This template instructs the model to pick out the\n",
    "# # exact sentences, tables, or figures from the context that support the given claim.\n",
    "# prompt_template = \"\"\"\n",
    "# You are a fact-checking assistant. Your task is to find the sentences, tables, or figures \n",
    "# in the context that best support the following claim.\n",
    "\n",
    "# Claim: {query}\n",
    "\n",
    "# Context:\n",
    "# {context}\n",
    "\n",
    "# Identify and return only the exact text from the context that supports the claim.\n",
    "# \"\"\"\n",
    "\n",
    "# Create the retriever once (outside the loop) to reuse for all queries.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Set up the RetrievalQA chain using our LLM, retriever, and custom prompt.\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    # Instead of passing your raw string, pass the PromptTemplate instance\n",
    "    chain_type_kwargs={\"prompt\": my_prompt}\n",
    ")\n",
    "\n",
    "\n",
    "logger.info(\"RetrievalQA chain set up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    max_new_tokens=128,  # Allow new tokens to be generated\n",
    "    device=-1  # Or use device=0 if you want to run on GPU (and you have resources)\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 20:19:13,501 - main_rag - INFO - Loaded 9 marketing claims.\n",
      "2025-04-11 20:19:13,538 - main_rag - INFO - RetrievalQA chain set up with prompt expecting 'question'.\n",
      "2025-04-11 21:20:45,272 - main_rag - INFO - Processed claim: Flublok ensures identical antigenic match with WHO... with 5 matches.\n",
      "2025-04-11 22:21:50,525 - main_rag - INFO - Processed claim: Flublok contains 3x the hemagglutinin (HA) antigen... with 5 matches.\n",
      "2025-04-11 23:24:26,187 - main_rag - INFO - Processed claim: Cell- and egg-based flu vaccines have the potentia... with 5 matches.\n",
      "2025-04-12 00:34:06,596 - main_rag - INFO - Processed claim: Recombinant technology leads to a broader immune r... with 5 matches.\n",
      "2025-04-12 01:43:52,287 - main_rag - INFO - Processed claim: Vaccination with a higher-dose recombinant flu vac... with 5 matches.\n",
      "2025-04-12 02:43:06,981 - main_rag - INFO - Processed claim: Flublok (quadrivalent) was evaluated in the pivota... with 5 matches.\n",
      "2025-04-12 03:39:49,167 - main_rag - INFO - Processed claim: Flublok is produced using a novel production platf... with 5 matches.\n",
      "2025-04-12 04:37:44,035 - main_rag - INFO - Processed claim: Recombinant HA antigens produced using BEVS have b... with 5 matches.\n",
      "2025-04-12 05:39:44,083 - main_rag - INFO - Processed claim: Flublok contains 45 micrograms (mcg) of HA per str... with 5 matches.\n",
      "2025-04-12 05:39:44,182 - main_rag - INFO - Completed evidence retrieval for all claims.\n"
     ]
    }
   ],
   "source": [
    "# Load marketing claims from a JSON file\n",
    "claims_path = os.path.join(\"data\", \"Flublok_Claims.json\")\n",
    "with open(claims_path, \"r\") as f:\n",
    "    claims_data = json.load(f)\n",
    "\n",
    "logger.info(f\"Loaded {len(claims_data['claims'])} marketing claims.\")\n",
    "\n",
    "# Create an empty output dictionary for results.\n",
    "results = {\"claims\": []}\n",
    "\n",
    "# Update your prompt template to use \"question\" instead of \"query\"\n",
    "from langchain.prompts import PromptTemplate\n",
    "my_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a fact-checking assistant. Your task is to find the sentences, tables, or figures \n",
    "in the context that best support the following claim.\n",
    "\n",
    "Claim: {question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Identify and return only the exact text from the context that supports the claim.\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "# Re-set up the RetrievalQA chain with the updated prompt\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": my_prompt}\n",
    ")\n",
    "logger.info(\"RetrievalQA chain set up with prompt expecting 'question'.\")\n",
    "\n",
    "# Process each marketing claim:\n",
    "for claim_item in claims_data[\"claims\"]:\n",
    "    claim = claim_item[\"claim\"]\n",
    "    \n",
    "    # Call the chain with the proper input key (\"question\")\n",
    "    response = qa_chain({\"query\": claim})\n",
    "    \n",
    "    # Build the output format for this claim.\n",
    "    claim_result = {\n",
    "        \"claim\": claim,\n",
    "        \"match_source\": []\n",
    "    }\n",
    "    \n",
    "    # Process the source documents returned by the chain.\n",
    "    for doc in response[\"source_documents\"]:\n",
    "        doc_source = doc.metadata.get(\"source\", \"Unknown Document\")\n",
    "        snippet = doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
    "        claim_result[\"match_source\"].append({\n",
    "            \"document_name\": doc_source,\n",
    "            \"matching_text\": snippet\n",
    "        })\n",
    "    \n",
    "    results[\"claims\"].append(claim_result)\n",
    "    logger.info(f\"Processed claim: {claim[:50]}... with {len(claim_result['match_source'])} matches.\")\n",
    "\n",
    "logger.info(\"Completed evidence retrieval for all claims.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-12 10:45:39,016 - main_rag - INFO - Results saved to results/rag_results.json\n",
      "{\n",
      "  \"claim\": \"Flublok ensures identical antigenic match with WHO- and FDA-selected flu strains.\",\n",
      "  \"match_source\": [\n",
      "    {\n",
      "      \"document_name\": \"data/Clinical Files/FlublokPI.pdf\",\n",
      "      \"matching_text\": \"96% of the in\\ufb02uenza isolates obtained from subjects in Study 1 were not antigenically matched to the strains represented in the vaccine. An exploratory analysis of VE of Flublok against all strains, r...\"\n",
      "    },\n",
      "    {\n",
      "      \"document_name\": \"data/Clinical Files/Treanor et al. (2011).pdf\",\n",
      "      \"matching_text\": \"Only 8 isolates in the study (<5% of the total) were antigeni- cally identical to the strains contained in the vaccine. All of these viruses were A/Wisconsin/67/2005-like H3N2 viruses. Two of these oc...\"\n",
      "    },\n",
      "    {\n",
      "      \"document_name\": \"data/Clinical Files/FlublokPI.pdf\",\n",
      "      \"matching_text\": \"The efficacy of Flublok Quadrivalent is relevant to Flublok because both vaccines are manufactured using the same process and have overlapping compositions (see Descrip- tion [11]). Study 6 evaluated ...\"\n",
      "    },\n",
      "    {\n",
      "      \"document_name\": \"data/Clinical Files/FlublokPI.pdf\",\n",
      "      \"matching_text\": \"would not be effective in children younger than 3 years of age (6). Safety and effectiveness of Flublok have not been established in children 3 years to less than 18 years of age. 8.5 Geriatric Use Da...\"\n",
      "    },\n",
      "    {\n",
      "      \"document_name\": \"data/Clinical Files/FlublokPI.pdf\",\n",
      "      \"matching_text\": \"reported (Flublok 1.3%, IIV3 0.8%) over the 30 day follow-up period. Flublok Quadrivalent Flublok Quadrivalent has been administered to and safety data collected from 4328 adults 50 years of age and o...\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output_json_path = os.path.join(\"results\", \"rag_results.json\")\n",
    "\n",
    "# Save the results dictionary into a JSON file.\n",
    "save_json(results, output_json_path)\n",
    "logger.info(f\"Results saved to {output_json_path}\")\n",
    "\n",
    "# Optional: Print a preview of the first claim's result.\n",
    "print(json.dumps(results[\"claims\"][0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
